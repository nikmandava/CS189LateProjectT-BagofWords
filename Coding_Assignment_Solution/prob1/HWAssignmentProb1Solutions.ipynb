{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Bag of Words for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation: In this problem we provide an introduction to a real world application of the Bag of Words Model: sentiment analysis and binary classification. The student will perform binary classification on two datasets: one Yelp Review dataset partitioned by low and highly rated reviews and another dataset of Airplane Tweets classified into positive and negative sentiment. The student starts off with data exploration. Afterwards, they create a simple logistic regression model with the only feature being word count, then implement bag of words features, then explore a number of modifications to the model in order to evaluate the tangible impact of using different variations and better understand the nuances of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the data set\n",
    "Here we explore the dataset of Yelp Reviews and Airplane Tweets. The Yelp dataset has a star rating of 1 to 5, so we extract the most polar reviews with 1 and 5 stars and classify them as -1 and 1 respectively. For Airplane Tweets, we translate the 'negative' and 'positive' sentiment labels into classes of -1 and 1. We initially load the data and do some exploratory analysis in order to learn more about the data we will be classifying and gain some insight into how to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to use Yelp Reviews dataset\n",
    "df = pd.read_csv('yelp_academic_dataset_review.csv') \n",
    "###\n",
    "\n",
    "### Uncomment this to use the Airplane Tweets dataset\n",
    "# df = pd.read_csv('Tweets.csv') \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply grab all the one star and five star data from the dataset here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the negative input: \n",
      "(10000, 9)\n",
      "Shape of the positive input: \n",
      "(10000, 9)\n",
      "Shape of the dataframe: \n",
      "(20000, 2)\n",
      "Data Frame of reviews:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21778</th>\n",
       "      <td>1</td>\n",
       "      <td>I struggled to pick between the 2 brazillian s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>1</td>\n",
       "      <td>Upon arriving we were greeted by an enthusiast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58457</th>\n",
       "      <td>-1</td>\n",
       "      <td>I have rented a car from these guys 3 times in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956</th>\n",
       "      <td>1</td>\n",
       "      <td>This guys awesome. Shows up quickly, 24hours a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23848</th>\n",
       "      <td>-1</td>\n",
       "      <td>If this place was in the south, it would be ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68173</th>\n",
       "      <td>-1</td>\n",
       "      <td>Bennett Property Management is awful. Working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43259</th>\n",
       "      <td>-1</td>\n",
       "      <td>The good: I read some reviews that the cutlets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37680</th>\n",
       "      <td>-1</td>\n",
       "      <td>Just not the same place it use to be since 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>1</td>\n",
       "      <td>Lazeez was absolutely fantastic! We had the gy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>1</td>\n",
       "      <td>I seriously LOVED this place!\\n\\nWe started wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21948</th>\n",
       "      <td>1</td>\n",
       "      <td>We had the bacon wrapped spicy meatloaf and be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>1</td>\n",
       "      <td>Cake batter, vanilla snow &amp; peanut butter!  \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>1</td>\n",
       "      <td>If you're an old-school video gamer, this is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>-1</td>\n",
       "      <td>Hate this place bad customer service the baske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18708</th>\n",
       "      <td>1</td>\n",
       "      <td>Tried Mom's for the lunch special: $6 (tax inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12185</th>\n",
       "      <td>1</td>\n",
       "      <td>Great drinking spot!! Very Divey and down home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>1</td>\n",
       "      <td>Delicious fast-casual restaurant. Everything t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16867</th>\n",
       "      <td>1</td>\n",
       "      <td>Eric was so sweet. He did such an excellent jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16175</th>\n",
       "      <td>1</td>\n",
       "      <td>I met an angel today at Chipotle and I am grat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35257</th>\n",
       "      <td>-1</td>\n",
       "      <td>I purchased a Groupon for this salon so I coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17322</th>\n",
       "      <td>1</td>\n",
       "      <td>Erica is great!  She has been cutting hair for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63080</th>\n",
       "      <td>-1</td>\n",
       "      <td>First of all I am not happy with their restaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28856</th>\n",
       "      <td>-1</td>\n",
       "      <td>Disaster:\\n\\n1. Food is nowhere near the quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37618</th>\n",
       "      <td>-1</td>\n",
       "      <td>Decided to give this place a try after hearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>1</td>\n",
       "      <td>I have become a huge fan of this little downto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6582</th>\n",
       "      <td>-1</td>\n",
       "      <td>Not recommended. I booked and was told I would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23126</th>\n",
       "      <td>-1</td>\n",
       "      <td>This is the place where all the rejects go whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17316</th>\n",
       "      <td>-1</td>\n",
       "      <td>I was so excited to try this place, as I had h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>-1</td>\n",
       "      <td>Has to be the WORST fish and chips I have ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoës is my favorite place to go. The food is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't usually write reviews, but in this cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39110</th>\n",
       "      <td>-1</td>\n",
       "      <td>DO NOT USE THIS COMPANY!!!!the customer servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>1</td>\n",
       "      <td>I spend just about every day here, and I love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17389</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been going to Color Me Glam Boutique for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>1</td>\n",
       "      <td>I ordered the chopped salad for my wife but I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424</th>\n",
       "      <td>1</td>\n",
       "      <td>Awesome food and great service! Get the chicke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>-1</td>\n",
       "      <td>The people here are extremely rude. No one wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22225</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolutely loved it. The food was very tasty a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>1</td>\n",
       "      <td>Stumbled across this place on my last day in V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71227</th>\n",
       "      <td>-1</td>\n",
       "      <td>I will have to ditto Tania S's review.  We did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11443</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!!! Had the stuffed french toast with c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20321</th>\n",
       "      <td>-1</td>\n",
       "      <td>This store doesn't know how to make a burrito....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54595</th>\n",
       "      <td>-1</td>\n",
       "      <td>Meh. Just  meh. In a town like this full of au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27840</th>\n",
       "      <td>-1</td>\n",
       "      <td>Went into Chili's for dinner.  Most of the tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19961</th>\n",
       "      <td>-1</td>\n",
       "      <td>From Le journal de Montreal http://www.journal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>-1</td>\n",
       "      <td>Totally rudeee the lady who answered the phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16265</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been to the Beverly Hills, Chicago and La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-1</td>\n",
       "      <td>Worst Sprint store in town. Their staff are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68647</th>\n",
       "      <td>-1</td>\n",
       "      <td>I ordered a bed frame over 3 months ago and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11782</th>\n",
       "      <td>-1</td>\n",
       "      <td>Despite how nice a business is, if it's unethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17492</th>\n",
       "      <td>-1</td>\n",
       "      <td>Don't know how this outfit got such a high rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18651</th>\n",
       "      <td>-1</td>\n",
       "      <td>My first experience was probably the worst Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42777</th>\n",
       "      <td>-1</td>\n",
       "      <td>I have faithfully been a customer twice a week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58672</th>\n",
       "      <td>-1</td>\n",
       "      <td>During my 45.00 oil change apparantly they neg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>-1</td>\n",
       "      <td>Thought they might put some effort forth since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>1</td>\n",
       "      <td>Beyond delicious cakes!  The cream cheese fros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21889</th>\n",
       "      <td>-1</td>\n",
       "      <td>I work at the mall and since they've opened I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12933</th>\n",
       "      <td>1</td>\n",
       "      <td>I went to autonation to purchase a used car I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16941</th>\n",
       "      <td>-1</td>\n",
       "      <td>Worst service ever that I experienced at wings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65731</th>\n",
       "      <td>-1</td>\n",
       "      <td>If you want to pay for water and get bad servi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                               text\n",
       "21778      1  I struggled to pick between the 2 brazillian s...\n",
       "9317       1  Upon arriving we were greeted by an enthusiast...\n",
       "58457     -1  I have rented a car from these guys 3 times in...\n",
       "8956       1  This guys awesome. Shows up quickly, 24hours a...\n",
       "23848     -1  If this place was in the south, it would be ou...\n",
       "68173     -1  Bennett Property Management is awful. Working ...\n",
       "43259     -1  The good: I read some reviews that the cutlets...\n",
       "37680     -1  Just not the same place it use to be since 200...\n",
       "5177       1  Lazeez was absolutely fantastic! We had the gy...\n",
       "9151       1  I seriously LOVED this place!\\n\\nWe started wi...\n",
       "21948      1  We had the bacon wrapped spicy meatloaf and be...\n",
       "3583       1  Cake batter, vanilla snow & peanut butter!  \\n...\n",
       "6740       1  If you're an old-school video gamer, this is d...\n",
       "6261      -1  Hate this place bad customer service the baske...\n",
       "18708      1  Tried Mom's for the lunch special: $6 (tax inc...\n",
       "12185      1  Great drinking spot!! Very Divey and down home...\n",
       "14182      1  Delicious fast-casual restaurant. Everything t...\n",
       "16867      1  Eric was so sweet. He did such an excellent jo...\n",
       "16175      1  I met an angel today at Chipotle and I am grat...\n",
       "35257     -1  I purchased a Groupon for this salon so I coul...\n",
       "17322      1  Erica is great!  She has been cutting hair for...\n",
       "63080     -1  First of all I am not happy with their restaur...\n",
       "28856     -1  Disaster:\\n\\n1. Food is nowhere near the quali...\n",
       "37618     -1  Decided to give this place a try after hearing...\n",
       "2313       1  I have become a huge fan of this little downto...\n",
       "6582      -1  Not recommended. I booked and was told I would...\n",
       "23126     -1  This is the place where all the rejects go whe...\n",
       "17316     -1  I was so excited to try this place, as I had h...\n",
       "12366     -1  Has to be the WORST fish and chips I have ever...\n",
       "1952       1  Zoës is my favorite place to go. The food is a...\n",
       "...      ...                                                ...\n",
       "10986      1  I don't usually write reviews, but in this cas...\n",
       "39110     -1  DO NOT USE THIS COMPANY!!!!the customer servic...\n",
       "3990       1  I spend just about every day here, and I love ...\n",
       "17389      1  I've been going to Color Me Glam Boutique for ...\n",
       "14312      1  I ordered the chopped salad for my wife but I ...\n",
       "9424       1  Awesome food and great service! Get the chicke...\n",
       "2093      -1  The people here are extremely rude. No one wil...\n",
       "22225      1  Absolutely loved it. The food was very tasty a...\n",
       "12057      1  Stumbled across this place on my last day in V...\n",
       "71227     -1  I will have to ditto Tania S's review.  We did...\n",
       "11443      1  Amazing!!! Had the stuffed french toast with c...\n",
       "20321     -1  This store doesn't know how to make a burrito....\n",
       "54595     -1  Meh. Just  meh. In a town like this full of au...\n",
       "27840     -1  Went into Chili's for dinner.  Most of the tab...\n",
       "19961     -1  From Le journal de Montreal http://www.journal...\n",
       "10105     -1  Totally rudeee the lady who answered the phone...\n",
       "16265      1  I've been to the Beverly Hills, Chicago and La...\n",
       "1683      -1  Worst Sprint store in town. Their staff are th...\n",
       "68647     -1  I ordered a bed frame over 3 months ago and it...\n",
       "11782     -1  Despite how nice a business is, if it's unethi...\n",
       "17492     -1  Don't know how this outfit got such a high rat...\n",
       "18651     -1  My first experience was probably the worst Sta...\n",
       "42777     -1  I have faithfully been a customer twice a week...\n",
       "58672     -1  During my 45.00 oil change apparantly they neg...\n",
       "18653     -1  Thought they might put some effort forth since...\n",
       "19562      1  Beyond delicious cakes!  The cream cheese fros...\n",
       "21889     -1  I work at the mall and since they've opened I ...\n",
       "12933      1  I went to autonation to purchase a used car I ...\n",
       "16941     -1  Worst service ever that I experienced at wings...\n",
       "65731     -1  If you want to pay for water and get bad servi...\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Uncomment to use Yelp Reviews dataset\n",
    "# Get one star reviews and label them with -1\n",
    "dfNegative = df[df['stars'] == 1]\n",
    "dfNegative = dfNegative.head(10000)\n",
    "dfNegative['stars'] = dfNegative['stars'].apply(lambda x: -1)\n",
    "\n",
    "# Get five star reviews and label them with 1\n",
    "print(\"Shape of the negative input: \")\n",
    "print(dfNegative.shape)\n",
    "dfPositive = df[df['stars'] == 5]\n",
    "dfPositive = dfPositive.head(10000)\n",
    "dfPositive['stars'] = dfPositive['stars'].apply(lambda x: 1)\n",
    "\n",
    "print(\"Shape of the positive input: \")\n",
    "print(dfPositive.shape)\n",
    "dfCombined = pd.concat([dfNegative, dfPositive], axis=0)\n",
    "dfCombined = dfCombined[['stars', 'text']]\n",
    "dfCombined=dfCombined.rename(columns = {'stars':'class'})\n",
    "###\n",
    "\n",
    "\n",
    "### Uncomment this to use the Airplane Tweets dataset\n",
    "# dfCombined = df[['airline_sentiment', 'text']]\n",
    "# dfCombined = dfCombined[dfCombined.airline_sentiment != 'neutral']\n",
    "# dfCombined['airline_sentiment'] = dfCombined['airline_sentiment'].replace(['positive','negative'],[1, -1])\n",
    "# dfCombined = dfCombined.rename(columns = {'airline_sentiment':'class'})\n",
    "# dfPositive = dfCombined[dfCombined['class'] == 1]\n",
    "# dfNegative = dfCombined[dfCombined['class'] == -1]\n",
    "# print(\"Shape of the negative input: \")\n",
    "# print(dfNegative.shape)\n",
    "# print(\"Shape of the positive input: \")\n",
    "# print(dfPositive.shape)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "# Randomly shuffling the data then dividing it into train and test sets\n",
    "dfCombined = dfCombined.sample(frac=1)\n",
    "print(\"Shape of the dataframe: \")\n",
    "print(dfCombined.shape)\n",
    "\n",
    "dfTrainset = dfCombined.head(int(len(dfCombined.index) * .8))\n",
    "dfTestset = dfCombined.tail(int(len(dfCombined.index) * .2))\n",
    "\n",
    "trainX = np.asarray(dfTrainset['text'])\n",
    "trainY = np.asarray(dfTrainset['class'])\n",
    "\n",
    "testX = np.asarray(dfTestset['text'])\n",
    "testY = np.asarray(dfTestset['class'])\n",
    "\n",
    "print('Data Frame of reviews:')\n",
    "\n",
    "\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run the below block multiple times to see different reviews and their respective class. Please comment below on what interesting aspects of the reviews you find associated with each class. What distinguishes between a classification of 1 and one of -1? Do so for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Orlando was very helpful and I was there a couple of times and he was very patient, I had trouble making up my mind what to order.  They have quality products and good customer service for all other people that work there.  I'm very happy with the pavers I bought for my patio re-do.\n",
      "\n",
      "Classification: 1\n"
     ]
    }
   ],
   "source": [
    "sample = dfTrainset.sample() \n",
    "print(\"Text: \" + sample['text'].values[0]  + \"\\n\")\n",
    "print(\"Classification: \" + str(sample['class'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: Reviews classified as negative have words such as 'rude', 'poor', 'avoid', and other words with negative implications. Additionally, even words like 'waiter' tend to show up in negative reviews because they generally mention things the waitter did wrong. On the other hand, reviews classified as positive contained words like 'nice', 'bomb', and 'helpful'. However, length doesn' seem to be as good an indicator as in the Airplane Tweets dataset.\n",
    "   <br><br>\n",
    "Airplane Tweets: Negative tweets seem to have a higher likelihood of having words with negative connotation like 'not' and 'worst,' as well as more punctuation such as quotation marks. They also seem to have a longer length on average. Positive tweets on the other hand have words like 'great' and even ':)' as well as tending to be shorter and having more exclamation marks.\n",
    "<br><br>\n",
    "Any meaningful answer that discusses words that are more commonly used in positive reviews vs\n",
    "negative reviews or length analysis will suffice\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Corpus Examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at all the text in our train dataset (corpus) in order to see what it contains. In the provided space below use a histogram to visualize the frequency of the 25 most common words. Then answer the questions that follow. Hint: The most_common function for Counters may come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allText = ' '.join(dfTrainset[\"text\"])\n",
    "words = allText.split() \n",
    "\n",
    "wordCounts = Counter()\n",
    "for word in words:\n",
    "    wordCounts[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all text:\n",
      "9326061\n",
      "Number of unique words:\n",
      "87831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 25 artists>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Length of all text:\")\n",
    "print(len(allText))\n",
    "print(\"Number of unique words:\")\n",
    "print(len(wordCounts))\n",
    "\n",
    "mostCommon = dict(wordCounts.most_common(25))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "ax.bar(mostCommon.keys(), mostCommon.values(), 1, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you notice about the most common words for both datasets? Do you think they are useful in classifying a review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "The most common words for both datasets seem to mainly contain stop words like 'the', 'is', 'and', and 'a'. The Twitter dataset also has '@united' and '@AmericanAirlines' as well as other corporations in its most common words. This makes sense as they are responding to those companies. These words do not seem to be a large predictor of class as they are probably widely used in both negative and positive reviews, as they are common in normal English speak and Tweets.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some of the least common words below. Define the variable least common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Part B\n",
    "leastCommon = dict(wordCounts.most_common()[:-10-1:-1])\n",
    "### End Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Strip.....wrong!).': 1, '(grissly': 1, \"flavor's\": 1, 'chicken\".': 1, 'Infortunetly': 1, 'faces!': 1, 'converter.': 1, 'pegs': 1, 'u.s.': 1, 'marginal.': 1}\n"
     ]
    }
   ],
   "source": [
    "print(leastCommon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you notice about the least common words for both datasets? Do you think they are useful in classifying a review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "The least common words for both datasets seem to mainly be gibberish and badly spelled or formatted words such as 'KTA', 'grissly', and '1-2888155964'. There are also many other words that are just as common with the same number of appearances: 1. These words do not seem useful in classifying a review because they are unlikely to show up again. Moreover, it may take away from other words in training by getting assigned a high magnitude weight in its lone appearance even if it will likely not show up again.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Identifying Unique Most Common Words of Each Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to find the most common words in each class that are not included in the other. Basically, we find the most common words in positive reviews (class = 1) that are not in the most common set of words for negative reviews (class = -1) and vice versa. Fill out the below code and answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in negative reviews: \n",
      "{'then': 2142, 'said': 3075, 'order': 2016, 'did': 2248, 'could': 2290, 'ordered': 1768, 'came': 2090, 'no': 3909, 'told': 3140, 'went': 2080, \"didn't\": 2615, 'customer': 1774, 'after': 2387, 'her': 2675, 'over': 2152, 'going': 1762, 'she': 3961, 'who': 1849, 'never': 2886, \"don't\": 2405, 'asked': 2314, 'minutes': 1854}\n",
      "\n",
      "Most common words in positive reviews: \n",
      "{'also': 1553, 'love': 1544, 'best': 1774, 'staff': 1198, 'some': 1460, 'great': 3288, 'recommend': 1257, '-': 1372, 'friendly': 1167, 'Great': 1211, 'has': 1425, \"it's\": 1247, 'made': 1148, 'always': 1721, 'can': 1671, 'come': 1071, 'really': 1749, 'nice': 1136, \"I've\": 1590, 'definitely': 1342, 'than': 1038, \"I'm\": 1184}\n"
     ]
    }
   ],
   "source": [
    "allTextPositive = ' '.join(dfPositive[\"text\"])\n",
    "wordsPositive = allTextPositive.split() \n",
    "\n",
    "### Begin Part C\n",
    "# Find the 100 most common words that are found in the five star reviews\n",
    "wordCountsPositive = Counter()\n",
    "for word in wordsPositive:\n",
    "    wordCountsPositive[word] += 1\n",
    "    \n",
    "mostCommonPositive = dict(wordCountsPositive.most_common(100))\n",
    "### End Part C\n",
    "\n",
    "\n",
    "\n",
    "allTextNegative = ' '.join(dfNegative[\"text\"])\n",
    "wordsNegative = allTextNegative.split() \n",
    "\n",
    "### Begin Part C\n",
    "# Find the 100 most common words that are found in the one star reviews\n",
    "wordCountsNegative = Counter()\n",
    "for word in wordsNegative:\n",
    "    wordCountsNegative[word] += 1\n",
    "mostCommonNegative = dict(wordCountsNegative.most_common(100))\n",
    "### End Part C\n",
    "\n",
    "### Begin Part C\n",
    "# Subtract sets in order to find the most common unique words for each set\n",
    "positiveUnique = { k : mostCommonPositive[k] for k in set(mostCommonPositive) - set(mostCommonNegative) }\n",
    "negativeUnique = { k : mostCommonNegative[k] for k in set(mostCommonNegative) - set(mostCommonPositive) }\n",
    "### End Part C\n",
    "\n",
    "print(\"Most common words in negative reviews: \")\n",
    "print(negativeUnique)\n",
    "print()\n",
    "print(\"Most common words in positive reviews: \")\n",
    "print(positiveUnique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you notice about these words above? Are they more respresentative of each classification? What words do you think are good indicators of each review class? What words are not so good? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: The most common words in negative reviews not in the positive reviews include 'asked', 'ordered', 'didn't', and 'customer'. This is because negative reviews tend to describe very specific situation where something goes wrong, as well as other negative words like 'never' and 'didn't'. The most common words in positive reviews include words such as 'love', 'best', and 'recommend', which all clearly demonstrate positive senttiment. So these words overall seem to be good indicators for each class, as opposed to the words we saw before. They also show up very often in reviews so will be good at predicting class. \n",
    "<br><br>\n",
    "Airplane Tweets: Some words that appear often in negative tweets but are not in the most often list for positive ttweets are 'how' and 'why'. This makes sense as a lot of complaints involve asking questions about something that went wrong. Other words in tthis set are 'Late', 'delayed', and 'Cancelled', which makes sense as these are negative words that would imply dissatisfaction and a negative response. On the other hand, some words that appear in the most common list for positive tweets but not negative are 'thanks', 'love', 'best', and so on. Again, these words make sense as they have a positive connotation and thus would appear more often in positive sentiment tweets. As a result, these words seem to be good indicators of negative/positive sentiment as they appear more often in their respective classes, and thus should be weighted as such in our model. On the other hand, stop words and words that do not appear often as above would no be great predictors of class.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing and Evaluating Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of the bag of words model, we first build a naive baseline model that tries to simply classification of the model purely based on the length of the review. Complete the code below and answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_featurize(review):\n",
    "    ### Begin Part D\n",
    "    # Featurize the data based on the length of the review. Hint: The feature vector should only have length 1.\n",
    "    return np.asarray([len(review)])\n",
    "    ### End Part D\n",
    "\n",
    "def trainModel(X_featurized, y_true):\n",
    "    ### Begin Part D\n",
    "    # Return a trained logistic regression model that can best predict y_true based on X_featurized\n",
    "    # We use the LogisticRegression Model we imported from scikit-learn to do so\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_featurized, y_true)\n",
    "    return model\n",
    "    ### End Part D\n",
    "\n",
    "def accuracyData(model, X_featurized, y_true):\n",
    "    ### Begin Part D\n",
    "    # Predict the data given the model and corresponding data. Return the accuracy \n",
    "    # as the percentage of values that were correctly classified. Also print a confusion\n",
    "    # matrix to help visualize the error. Hint: Look at sklearn.metrics.confusion\n",
    "    y_predict = model.predict(X_featurized)\n",
    "    total_num = len(y_true)\n",
    "    total_correct = np.sum([1 if y_predict[i] == y_true[i] else 0 for i in range(len(y_predict))])\n",
    "    total_incorrect = total_num - total_correct\n",
    "    accuracy = total_correct / total_num\n",
    "    print(sklearn.metrics.confusion_matrix(y_true, y_predict, labels=[-1, 1]))\n",
    "    print(accuracy)\n",
    "    ### End Part D\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[ 913 1108]\n",
      " [ 520 1459]]\n",
      "0.593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.593"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Begin Part D\n",
    "# Featurize the training data and then train a model on it. \n",
    "# Afterwards, featurize the test data and evaluate the model on it.\n",
    "# Use the functions you made above to do so\n",
    "print(\"Beginning Train Featurization\")\n",
    "featurized_data = np.array(list(map(baseline_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "model = trainModel(featurized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturized_data = np.array(list(map(baseline_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(model, testFeaturized_data, np.asarray(dfTestset[\"class\"]))\n",
    "### End Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did you get as your accuracy? Does that surprise you? Why or why not? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: The accuracy for this baseline model is 0.593. This accuracy makes a lot of sense as length did not seem to be a major differentiator between positive and negative reviews, but it does have a non-insignificant role as a predictor, since it was better than a random accuracy of 0.5.\n",
    "<br><br>\n",
    "Airplane Tweets: The overall accuracy for the baseline model with the only feature of length was 0.796. This accuracy was actually surprisingly higher than expected as while length of tweet seemed somewhat correlated with sentiment, I did not realize it would be this significant.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the bag of words featurization below based on the provided lecture. Please complete the following code segments and answer the following questions. For the next few part and every bag of words model in this homework, your accuracy should be above or close to 90%. If it is not, then you may be implementing wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a wordsOrdered list that contains all words in the train data that show up more\n",
    "# than one time. Each word count should be in its respective place in the feature vector.\n",
    "\n",
    "modifiedCounter = Counter(el for el in wordCounts.elements() if wordCounts[el] > 1)\n",
    "wordsOrdered = [key for key, _ in modifiedCounter.most_common()]\n",
    "\n",
    "def bag_of_words_featurize(review):\n",
    "    ### Begin Part E\n",
    "    # Code the featurization for the bag of words model. Return the corresponding vector\n",
    "    reviewWords = review.split() \n",
    "    vec = np.zeros(len(modifiedCounter))\n",
    "    for word in reviewWords:\n",
    "        if word in wordsOrdered:\n",
    "            vec[wordsOrdered.index(word)] += 1\n",
    "    return vec\n",
    "    ### End Part E        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below script and see how well the bag of words model performs. Warning: this block may\n",
    "around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[1932   89]\n",
      " [  89 1890]]\n",
      "0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "currBagFeaturized_data = np.array(list(map(bag_of_words_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "currBagModel = trainModel(currBagFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBag_data = np.array(list(map(bag_of_words_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(currBagModel, testFeaturizedBag_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy? Does that surprise you? Why did it perform as it did? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: This bag of words model achieved a test accuracy of 0.9555. This was pretty surprising as it seemed to do much better than expected, without the model leaning to favoring a class as evidenced by the confusion matrix.\n",
    "<br><br>\n",
    "Airplane Tweets: The basic bag of words model achieved an accuracy of 0.912. This was not particularly surprising as it seemed that there were words as described before that were good indicators of sentiment, so those probably played a large role in getting a decent accuracy.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intermed = dict(enumerate(wordsOrdered))\n",
    "wordPosition = {y:x for x,y in intermed.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F: Examining Bag of Words Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a function that gets the weight of a word feature below in the weight vector generated from the logistic regression model with bag of words featurization. Answer the question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightOfWords(word):\n",
    "    if word not in wordPosition.keys():\n",
    "        print(\"Word does not exist in model, no weight is assigned to it\")\n",
    "        return\n",
    "    return currBagModel.coef_[0][wordPosition[word]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2448829917949824"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try different words here\n",
    "weightOfWords('slow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List three words that have positive weights. List three that have negative weights. Explain why that makes sense. Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews:\n",
    "<br> 'great': 1.831\n",
    "<br> 'recommend': 0.479\n",
    "<br> 'love': 1.282\n",
    "<br> 'hate': -0.536\n",
    "<br> 'slow': -1.245\n",
    "<br> 'ordered': -0.762\n",
    "<br><br>\n",
    "Airplane Tweets:\n",
    "<br> 'good': 1.467\n",
    "<br> 'amazing': 1.608\n",
    "<br> 'fast': 0.515\n",
    "<br> 'delayed': -1.470\n",
    "<br> 'bad': -0.55\n",
    "<br> 'terrible': -1.142\n",
    "<br> These weights make sense as since we described above, words with positive connotation that we would relate to a positive sentiment seem to have positive weights, some of them larger in magnitude than others, and words with negaive connotations one would associate with a bad experience have negative weights to guide the response to a negative classification.\n",
    "<br><br>\n",
    "    \n",
    "Any set of words that works is sufficient. Ex: 'him', 'her', 'bad' are negatively weighted ...\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G: Binary Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are times when we only want to identify whether a word is in a review or not and disregard the number of times it has shown up in the review. In this case, we find binary bag of words more useful that our regualar bag of words model. Hypothesize which model should run better given the examination of the dataset. Complete the code below and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_binary_featurize(review):\n",
    "    ### Begin Part G\n",
    "    reviewWords = review.split() \n",
    "    vec = np.zeros(len(modifiedCounter))\n",
    "    for word in reviewWords:\n",
    "        if word in wordsOrdered:\n",
    "            vec[wordsOrdered.index(word)] = 1\n",
    "    return vec\n",
    "    ### End Part G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below script and see how well the bag of words model performs. Warning: this block may\n",
    "around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[1926   95]\n",
      " [ 101 1878]]\n",
      "0.951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.951"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "currBinBagFeaturized_data = np.array(list(map(bag_of_words_binary_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "currBinBagModel = trainModel(currBinBagFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBinBag_data = np.array(list(map(bag_of_words_binary_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(currBinBagModel, testFeaturizedBinBag_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected? How did it compare to the regular Bag of Words model? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: The binary bag of words model here resulted in a training accuracy of 0.951. This isn't too far off so while somewhat unexpected it is not a big shock. This is likely because multiple repetitions of the same word actually should have lead to a larger weight and altered the prediction.\n",
    "<br><br>\n",
    "Airplane Tweets: The accuracy here was 0.915 for binary bag of words, higher than that of original bag of words. This makes sense as it is possible that a negative word that appears multiple times will be weighted lower if it appears in a negative response during training, so binary bag of words maintains a more accurate sense of the sentiment of a word.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part H: Bag of Words Negative Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are times where we also want to identify negative words as separate features instead of regular features. For example if we get a review: \"The food is not good\", the word \"good\" is used in a negative connotation and should be treated as such. Thus we make new features for the negative of each of our chosen words. Complete the code below and answer the following questions. Hint: Try doubling the size of the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_neg_featurize(review):\n",
    "    ### Begin Part H\n",
    "    # Remember, we now want a representation of each word such as 'happy' and 'NEGATE_happy'.\n",
    "    # One way to do so is by making the feature vector twice the size to store each 'NEGATE_' of a word\n",
    "    # The first half of the vector can be the normal vocab and the last half can be the negated vocab \n",
    "    reviewWords = review.split() \n",
    "    vec = np.zeros(len(modifiedCounter)*2)\n",
    "    isNegative = False\n",
    "    for word in reviewWords:\n",
    "        if word in wordsOrdered:\n",
    "            if isNegative:\n",
    "                vec[wordsOrdered.index(word)+len(modifiedCounter)] += 1\n",
    "            else:\n",
    "                vec[wordsOrdered.index(word)] += 1\n",
    "            isNegative = False\n",
    "        if \"n't\" in word or word == \"not\":\n",
    "            isNegative = True\n",
    "    return vec\n",
    "    ### End Part H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below script and see how well the bag of words model performs. Warning: this block may\n",
    "around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[1935   86]\n",
      " [  93 1886]]\n",
      "0.95525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95525"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "neg_data = np.array(list(map(bag_of_words_neg_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "negModel = trainModel(neg_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedNeg_data = np.array(list(map(bag_of_words_neg_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(negModel, testFeaturizedNeg_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How did this model perform? Is it as expected? Why did it perform this way? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: The negative bag of word featurization had a test accuracy of 0.955. This is basically the same as normal bag of words and the model itself did not pick on any differences, which was somewhat unexpected again but is probably a function of the dataset itself.\n",
    "<br><br>\n",
    "Airplane Tweets: This model actually did very similar to normal bag of words with an acccuracy of 0.912. This was somewhat unexpected as not negating words like 'not good' and treating them as an instance of not and an instance of good was thought to have a bad impact on test accuracy. However, in this case it did not, potentially due to a more advanced data cleaning. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Negative Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the code below and answer the questions below for combining the two features we worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_neg_binary_featurize(review):\n",
    "    ### Begin Part I\n",
    "    reviewWords = review.split() \n",
    "    vec = np.zeros(len(modifiedCounter)*2)\n",
    "    isNegative = False\n",
    "    for word in reviewWords:\n",
    "        if word in wordsOrdered:\n",
    "            if isNegative:\n",
    "                vec[wordsOrdered.index(word)+len(modifiedCounter)] = 1\n",
    "            else:\n",
    "                vec[wordsOrdered.index(word)] = 1\n",
    "            isNegative = False\n",
    "        if \"n't\" in word or word == \"not\":\n",
    "            isNegative = True\n",
    "    return vec\n",
    "    ### End Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below script and see how well the bag of words model performs. Warning: this block may around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[1932   89]\n",
      " [  98 1881]]\n",
      "0.95325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95325"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "negbin_data = np.array(list(map(bag_of_words_neg_binary_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "negBinModel = trainModel(negbin_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedNegBin_data = np.array(list(map(bag_of_words_neg_binary_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(negBinModel, testFeaturizedNegBin_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was the result as expected? Why or why not? Answer for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Yelp Reviews: 0.953 This result was as expected at a happy medium in between the binary and negation modifications for the feaures, albeit still worse than the normal bag of words. As can be seen, for some datasets, especially those with clear divides between classes and strong word indicators, bag of words without any modifications performed better. You will see in the next part an example with more nuance (including 2 and 4 stars) where it helps to make these modifications. As usual, both should be tried and tested on a validation set to determine which is better. \n",
    "<br><br>\n",
    "Airplane Tweets: As expected, this bag of words model combining both the negation and binary modifications did right in the middle of the two independently with an accuracy of 0.914. This makes sense, although it appears that including negated features had a negative effect on the binary bag of words model, potentially due in part to the specific dataset we generated.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part J (OPTIONAL): Enhanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get extra credit, Try to create some sort of featurization below that will reach an accuracy of .97 or higher for either model. Ideas to keep in mind are the Bigram model that was discussed in the notes that takes consecutive words into account as well as methods to increase the number of features we use. Good luck!!\n",
    "HINT: You can combine additional features like length with existing bag of words features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_extra_credit_featurize(review):\n",
    "    ### Begin Part J\n",
    "    # User solution!\n",
    "    ### End Part J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "ExtraBagFeaturized_data = np.array(list(map(bag_of_words_extra_credit_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "ExtraBagModel = trainModel(ExtraBagFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBinBag_extra = np.array(list(map(bag_of_words_extra_credit_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(ExtraBagModel, testFeaturizedBinBag_extra, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What features did you add? Why did you do so? What was your accuracy percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "Any response here that both obtains an accuracy above 0.97 on a dataset and discusses either cleaning the data better or combining additional features such as length of response, number of exclamation marks, number of question marks, or additional sentiment dictionaries such as The Sentiment Lexicon from the University of Pittsburgh receives full extra credit here.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">ONLY RUN BELOW CODE IF YOU ARE ON THE YELP DATASET</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating Yelp Model with Less Polar Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be performing a similar analysis on the Yelp Dataset but including both 1 star and 2 star reviews as the negative class and 4 star and 5 star reviews as the positive class. This way there will be less of a clear divide between the two classes and students should see how adapting the bag of words model can prove beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the ones input: \n",
      "(10000, 9)\n",
      "Shape of the fives input: \n",
      "(10000, 9)\n",
      "Data Frame of reviews:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117895</th>\n",
       "      <td>1zsM7weLS8fNHomDAqCh4Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-30 21:01:16</td>\n",
       "      <td>0</td>\n",
       "      <td>8HUD9mFT5ulcXWsJ0tvlHA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Wait for a table wasn't bad for a Sunday brunc...</td>\n",
       "      <td>0</td>\n",
       "      <td>F3wv7xhvjQFHAsD6mubsIQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44320</th>\n",
       "      <td>yBGqf8l9NOM3vZFnlxcgzQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-07-09 18:55:34</td>\n",
       "      <td>3</td>\n",
       "      <td>cVtFum2XFprf5wVQhWB6WA</td>\n",
       "      <td>-1</td>\n",
       "      <td>What a disappointment!  I was all excited to s...</td>\n",
       "      <td>10</td>\n",
       "      <td>6b4yYexmPQglmNdNum531Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73075</th>\n",
       "      <td>K5sUVFSGFEZosixSXgx5sw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-10 21:08:51</td>\n",
       "      <td>0</td>\n",
       "      <td>-5Qc2230M8_Olotphs7BuA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Burger was subpar and the fries were cold, did...</td>\n",
       "      <td>1</td>\n",
       "      <td>zeHuIVREdQtAaiJRpb4low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22447</th>\n",
       "      <td>IuW6aZ8XYtxkdvHJoVHlfw</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-09 21:18:32</td>\n",
       "      <td>0</td>\n",
       "      <td>olmjKR6uzlpG-8SQIcjdHw</td>\n",
       "      <td>1</td>\n",
       "      <td>I love aloha salon! Not only their service is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>QAdtpOZjG84043dqtXfESg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30171</th>\n",
       "      <td>9Jo1pu0y2zU6ktiwQm6gNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-07 02:31:32</td>\n",
       "      <td>0</td>\n",
       "      <td>k_1ITZFaoCA-FtIrBo0LvQ</td>\n",
       "      <td>1</td>\n",
       "      <td>I only had their spicy poke bowl, but I went t...</td>\n",
       "      <td>0</td>\n",
       "      <td>EBkNxxo181SpO1CYinI3xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94841</th>\n",
       "      <td>nxlgrjTdUhvTg_3Ai0JKqw</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-10 22:25:30</td>\n",
       "      <td>0</td>\n",
       "      <td>gX8paNzzNOH_8RCg2gKlhA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Not what I expected. It is ordinary, nothing r...</td>\n",
       "      <td>0</td>\n",
       "      <td>kjzg7jTm6tWhETeJ3xDqZw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14195</th>\n",
       "      <td>4IGaWH9jUYMtP2uHIFEqFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-01 17:06:26</td>\n",
       "      <td>0</td>\n",
       "      <td>P30fI8uVkPFmQCLJ0PqqHA</td>\n",
       "      <td>1</td>\n",
       "      <td>This is actually one of the easier airports to...</td>\n",
       "      <td>1</td>\n",
       "      <td>sh3V6hnNMLVV9YwFA9QNaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18383</th>\n",
       "      <td>8nDEOGVVvReXFJ2zjPh4Pw</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-09 15:57:45</td>\n",
       "      <td>0</td>\n",
       "      <td>7ObEq54s3BVYa4k0kW1Ktg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Not the best of attitudes, I thought this plac...</td>\n",
       "      <td>1</td>\n",
       "      <td>Y8_yCJ7N7LyqqJ-rSxd4iQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>x8h3A9dOKux99qAp6Bakbg</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-22 20:40:47</td>\n",
       "      <td>1</td>\n",
       "      <td>40IOk-VBxiq7d-KUlUlC9w</td>\n",
       "      <td>-1</td>\n",
       "      <td>How is In the Company of Thieves?  It depends ...</td>\n",
       "      <td>4</td>\n",
       "      <td>TIll8A0a_GqegEm4h3yiHw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101896</th>\n",
       "      <td>6ZIHxvFTHC1pvAzAS0uLDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-30 00:43:29</td>\n",
       "      <td>1</td>\n",
       "      <td>MybJ5GnsoSSDX9P8Ydoc2g</td>\n",
       "      <td>-1</td>\n",
       "      <td>I ordered a #2 pork roll sandwich.   I nearly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>oAJzUPW-XtpEQyle_QXLkA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16007</th>\n",
       "      <td>J7fekWie4ZwR03AZVBisFw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-04 01:37:20</td>\n",
       "      <td>0</td>\n",
       "      <td>DFrsI3rLHQyDm1m6jvU18A</td>\n",
       "      <td>-1</td>\n",
       "      <td>My husband and I were staying at a hotel near ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go0FTv1slZ128s_Y24Igdw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>KalAJyO0Zpg3K1wVwYXBHA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-06-13 22:04:03</td>\n",
       "      <td>0</td>\n",
       "      <td>snl4SU-FQB9V6NEzisTbcQ</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bad experience!  Blackened salmon sandwich app...</td>\n",
       "      <td>2</td>\n",
       "      <td>0lZTY9OnTEc5gaBPRGvgeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75878</th>\n",
       "      <td>iuSq6jpt-r-7JxqXE5hK6g</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-04 13:17:31</td>\n",
       "      <td>1</td>\n",
       "      <td>U1Zs5yQi0j_ab2LpWncTsA</td>\n",
       "      <td>-1</td>\n",
       "      <td>I've been to Heart and Soul two times and both...</td>\n",
       "      <td>3</td>\n",
       "      <td>NUqAqRPyWOgPDdMdhtSebw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4ZbRwCB9oGibxK21MUZKHA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-04 22:27:08</td>\n",
       "      <td>0</td>\n",
       "      <td>E5iXQGD_x_Fyee1kOKgGTw</td>\n",
       "      <td>-1</td>\n",
       "      <td>I went into this store yesterday and it was ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>ffMc-TmUUhEbj5LLNILB4A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27338</th>\n",
       "      <td>_iGvLfEsqDwPUxRUAe6tUw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-03 03:01:22</td>\n",
       "      <td>0</td>\n",
       "      <td>DHXZOvG6urLihqCsdL59Lw</td>\n",
       "      <td>-1</td>\n",
       "      <td>Poor salesmanship,  deceptive during trade-in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>EgbeJrycEtSkps8UbJRpaQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>6TvB1PZCY1Ap2S-yNJPs4w</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-14 04:11:12</td>\n",
       "      <td>0</td>\n",
       "      <td>u_OpkjRC-wY8x16dmjgGew</td>\n",
       "      <td>-1</td>\n",
       "      <td>Aaliyah at the restaurant was super rude . May...</td>\n",
       "      <td>0</td>\n",
       "      <td>nh6YUBtU-azoYVKDK8O7KQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>tWiFat101ID5w_wgAPMXhA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-18 04:20:13</td>\n",
       "      <td>0</td>\n",
       "      <td>T1yrvyOcdsvm0wOMNSrZww</td>\n",
       "      <td>1</td>\n",
       "      <td>This place is an institution. I have been goin...</td>\n",
       "      <td>0</td>\n",
       "      <td>Owo6mggrsd4cuKlC0wWQ6w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39270</th>\n",
       "      <td>LGEIsxeJQATo9J1IA-TEdA</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-09 01:36:28</td>\n",
       "      <td>1</td>\n",
       "      <td>mbn_GyffLzGUTFeWwT06Xw</td>\n",
       "      <td>-1</td>\n",
       "      <td>This place used to be 5 stars.  I've been goin...</td>\n",
       "      <td>2</td>\n",
       "      <td>Z8dN-_8IMZ3FnHg2AhGlXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14418</th>\n",
       "      <td>nvBhlpH8TWbCl70_30gqxg</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-16 00:17:09</td>\n",
       "      <td>1</td>\n",
       "      <td>iUkMdJ3mdbCxhhySwIHT2A</td>\n",
       "      <td>-1</td>\n",
       "      <td>Why is this theater so filthy? Dirty! Trash an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1_CkjgX5iGjbVpW8O-GU5Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63863</th>\n",
       "      <td>3GfdCuI0YCc5U3rLLLPHUw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-18 16:50:10</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1gJnlSBzfd6sxw39jjuNA</td>\n",
       "      <td>-1</td>\n",
       "      <td>I would have given the place a rave review if ...</td>\n",
       "      <td>0</td>\n",
       "      <td>AdgrOZj2hrh0HlGyu7JWHg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61884</th>\n",
       "      <td>u_vPjx925UPEG9DFOAAvFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-07 17:43:48</td>\n",
       "      <td>0</td>\n",
       "      <td>CLis0AoUs5Coi_fAye16tQ</td>\n",
       "      <td>-1</td>\n",
       "      <td>Very disappointed, we stayed on the 14th floor...</td>\n",
       "      <td>0</td>\n",
       "      <td>SENiX02vQAUqFUB-NsITmQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>_orp_eadrrigWixdMfpB9A</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-26 22:56:58</td>\n",
       "      <td>1</td>\n",
       "      <td>a1E8gNIp1bs9lkUWr8m4ZA</td>\n",
       "      <td>1</td>\n",
       "      <td>Dr. McCoy is awesome and his team is also very...</td>\n",
       "      <td>0</td>\n",
       "      <td>M0UiTAlVZx317KGSZ5lxLg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49311</th>\n",
       "      <td>4kDLEb1OgE7IrO54lCkn3A</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-26 20:15:53</td>\n",
       "      <td>0</td>\n",
       "      <td>fmlVWFzycbqQDqkMIp88Ew</td>\n",
       "      <td>-1</td>\n",
       "      <td>Went with a few friends since everywhere else ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ImiPjQTtcXq400p6djLrtA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50477</th>\n",
       "      <td>YHXczxm4W3BkGT-z7vZBBw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-18 14:58:10</td>\n",
       "      <td>0</td>\n",
       "      <td>i5WYsZnf-r_Te_932rZwdQ</td>\n",
       "      <td>-1</td>\n",
       "      <td>I was pretty excited to hear about a new Chati...</td>\n",
       "      <td>2</td>\n",
       "      <td>zWWcik1fRPZviBCQLC26FQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97933</th>\n",
       "      <td>uh7DUWtPoZkuEE05fghJ_w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-22 05:53:56</td>\n",
       "      <td>0</td>\n",
       "      <td>LCBBrcyQVwOoDmDEG51t4Q</td>\n",
       "      <td>-1</td>\n",
       "      <td>Chic.... to enjoy ambiance this is the place ....</td>\n",
       "      <td>0</td>\n",
       "      <td>2qkXXaDBo_MdSBHj8Mdj0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>i6gKYG_YFuF5o90jPuWYvw</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-15 02:47:56</td>\n",
       "      <td>0</td>\n",
       "      <td>QaKD8EQaiwHLAuCO42KN8g</td>\n",
       "      <td>-1</td>\n",
       "      <td>Giving them 2 stars because they have made the...</td>\n",
       "      <td>0</td>\n",
       "      <td>zyg4-MFtfPWmwucVazSjfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25492</th>\n",
       "      <td>Rfu2q_Jc0fAGP_5ecIar3g</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-29 04:13:45</td>\n",
       "      <td>0</td>\n",
       "      <td>uHnCz4_jvgcDruzb8eItoA</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me say this... my total package cost me $4...</td>\n",
       "      <td>14</td>\n",
       "      <td>N_8Ad4o7pgBbHDG7AC11wA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28989</th>\n",
       "      <td>ppobG2P-YmqTPy0s4MTRtA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-15 00:51:47</td>\n",
       "      <td>0</td>\n",
       "      <td>MlyUSNbTES7bxh6oHL5zmA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Maybe we were here on an off-day, but my party...</td>\n",
       "      <td>1</td>\n",
       "      <td>No1Qn10ByvTfDVUKDUB3aA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>eaNenRk_liZBERFFLCXqqQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-12 06:28:30</td>\n",
       "      <td>0</td>\n",
       "      <td>aBD1oLFaTN7LAcvOVcfHaw</td>\n",
       "      <td>1</td>\n",
       "      <td>I don't usually do reviews but this is 5 stars...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ng5lLOfZjI-pbPbnLw5EmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>Os1n1_idfw9vv9kwULGJnQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-04 04:52:31</td>\n",
       "      <td>0</td>\n",
       "      <td>HMhDTuz5mD6Gv9JpYm3SlQ</td>\n",
       "      <td>1</td>\n",
       "      <td>Someone please explain what I would have done ...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA46YFb2JxWvz1c1ApZ9ZQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110664</th>\n",
       "      <td>ijg7qQCYnhUWBd5JUxbfvA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-05 20:26:03</td>\n",
       "      <td>0</td>\n",
       "      <td>_R052l9dVVKd80aCK-BqWA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Food was great. $5 Bloody Mary was Good. Beer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mGHG6Qh6RQh4dK_eR0WRsg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>oz-U184llqjVIt398hLntQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-18 19:25:15</td>\n",
       "      <td>1</td>\n",
       "      <td>OPZKeZyhvoShzu6LRQ3kig</td>\n",
       "      <td>1</td>\n",
       "      <td>As a gay male walking into this restaurant I m...</td>\n",
       "      <td>1</td>\n",
       "      <td>89ExXwHanHBxx04yMSZmNw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>dPGs5b0N9MarZjVgQVelGQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-07 02:16:32</td>\n",
       "      <td>0</td>\n",
       "      <td>7_D5oAsiAgFMWQfkvrgv4Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Very nice place. Service tends to be very good...</td>\n",
       "      <td>0</td>\n",
       "      <td>vOPnC4XPRSknykbxYIG8Hw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48086</th>\n",
       "      <td>u_vPjx925UPEG9DFOAAvFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-05 02:52:10</td>\n",
       "      <td>0</td>\n",
       "      <td>Ke_BLSjY6V12i1D5s3Ieeg</td>\n",
       "      <td>-1</td>\n",
       "      <td>After a long drive we got to the hotel on 3/30...</td>\n",
       "      <td>0</td>\n",
       "      <td>Qhmk2ieq8RpckAV8x2cD-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38772</th>\n",
       "      <td>1lLJDy73uBp_I2LJ0B0Fkw</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-16 16:50:15</td>\n",
       "      <td>0</td>\n",
       "      <td>2UvBQ5XpA9FAvf9hIDSJaw</td>\n",
       "      <td>1</td>\n",
       "      <td>I have to admit, there is absolutley  nothing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jx4_0MDOY-FW4G7yW49WxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44664</th>\n",
       "      <td>0j7VWa5uGebj_94C1K2i2g</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-08 20:24:33</td>\n",
       "      <td>0</td>\n",
       "      <td>oGGqWgyeNcOLYmUWfDPQWA</td>\n",
       "      <td>-1</td>\n",
       "      <td>GOD I HATE WALMART, and this one is no excepti...</td>\n",
       "      <td>2</td>\n",
       "      <td>o9MwJLcMUJ48LRVIUmr6BQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17089</th>\n",
       "      <td>3GfdCuI0YCc5U3rLLLPHUw</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-21 09:38:08</td>\n",
       "      <td>0</td>\n",
       "      <td>ndtKjKcT8Biykk3Jeb3Dag</td>\n",
       "      <td>1</td>\n",
       "      <td>One of the newer izakayas in the valley. They ...</td>\n",
       "      <td>2</td>\n",
       "      <td>gqpnDoFx42U5NdtejYfKOg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>KUOa1acSFn6DkO9jp-sn6A</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-06 18:52:41</td>\n",
       "      <td>1</td>\n",
       "      <td>2G7GKwpWJJviVErk6-Csbw</td>\n",
       "      <td>-1</td>\n",
       "      <td>This Famous Dave's was awful!  The only reason...</td>\n",
       "      <td>1</td>\n",
       "      <td>w8rOqeKZCPtDu-DXXSZIwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18096</th>\n",
       "      <td>e1SSSU7IUrC3R_cmw4vW9g</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-13 13:29:04</td>\n",
       "      <td>0</td>\n",
       "      <td>D1IxK6Vcztw3P3CKyLek2A</td>\n",
       "      <td>1</td>\n",
       "      <td>Un très beau et accueillant café, la meilleure...</td>\n",
       "      <td>0</td>\n",
       "      <td>TuSA83Ob6un1m0LXl2JHnQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>k4jX-Xe9dFu2pmdnlrcwgA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-28 21:50:03</td>\n",
       "      <td>0</td>\n",
       "      <td>UUSHvjTqoQ6bPx69XtDF_g</td>\n",
       "      <td>-1</td>\n",
       "      <td>My husband and I went here after stopping at t...</td>\n",
       "      <td>0</td>\n",
       "      <td>PjlYINWKAxdWvL1zz4UlJg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>4gwh0q7JsdzHIm_pdYUlZg</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-01-03 17:18:44</td>\n",
       "      <td>0</td>\n",
       "      <td>SWEBe2_Z_Stc2R8Hu0C2LA</td>\n",
       "      <td>1</td>\n",
       "      <td>impeccable service. delectable food. this plac...</td>\n",
       "      <td>12</td>\n",
       "      <td>zSwb7qNpSgU3ekHMpiHsOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33982</th>\n",
       "      <td>F2pfjAZ_3dMTGCKv6c5wOw</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-28 21:25:37</td>\n",
       "      <td>0</td>\n",
       "      <td>2j9o2wkdoC4hU5ELdKKsxw</td>\n",
       "      <td>1</td>\n",
       "      <td>Have been wanting to go here for quite some ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>j2FfSIomcaNYvv8ywEIzQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101987</th>\n",
       "      <td>seYvTmOZGJ2IAMdfQa8pkg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-10 20:10:11</td>\n",
       "      <td>0</td>\n",
       "      <td>RMQ9PFcEDotH8pf0FvI4mg</td>\n",
       "      <td>-1</td>\n",
       "      <td>This place needs to make up its mind! Sometime...</td>\n",
       "      <td>1</td>\n",
       "      <td>VFWymyNU_Bp8VCl9_RD8og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50685</th>\n",
       "      <td>YidWQ-CipHgGpA8jygsPpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-21 02:30:15</td>\n",
       "      <td>0</td>\n",
       "      <td>rHlUTLFvQgguRiK1xoF_LQ</td>\n",
       "      <td>-1</td>\n",
       "      <td>Had an appointment to get my dogs bathed at th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2eNy5pf5ctWxouGGaASTOQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15252</th>\n",
       "      <td>Te8ubqIn8aH2uplVhvMntw</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 22:09:51</td>\n",
       "      <td>0</td>\n",
       "      <td>Ltfz2_Tibu0LQVp7PJYVeQ</td>\n",
       "      <td>1</td>\n",
       "      <td>The gelato tastes great. The price did not jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>2pRDsLUqTK0o9ePcIiyy_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>hUgaylJ8gR3BNMcFiASQSA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-30 01:37:56</td>\n",
       "      <td>0</td>\n",
       "      <td>QiXtP62NeBMnqri3d8oz-g</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Matt Lemm from Funny Magic For Kids has ...</td>\n",
       "      <td>3</td>\n",
       "      <td>SBhmnRD-w_xgQ-RQRRCz5w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69257</th>\n",
       "      <td>ShUh_MMkaVp_KXCtNjPvXA</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-12 13:58:54</td>\n",
       "      <td>0</td>\n",
       "      <td>vfkijFVcBvlcNzcMTqp-ZQ</td>\n",
       "      <td>-1</td>\n",
       "      <td>The space is nice. The dry-rub ribs were good,...</td>\n",
       "      <td>0</td>\n",
       "      <td>7tRj6BKT1tTlZ1AbmZWAmw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>vDqKDzGuHXBznrC1HlgW1A</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-25 17:47:01</td>\n",
       "      <td>0</td>\n",
       "      <td>DJyXRQl7rmqAnQGnq87IoA</td>\n",
       "      <td>-1</td>\n",
       "      <td>I'm very upset with this practice. I have trie...</td>\n",
       "      <td>0</td>\n",
       "      <td>-fwrHX9L3a0IlU3wkhxd2w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36281</th>\n",
       "      <td>ME6D5nLlfG0xZCtICOYDuw</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-04 15:28:11</td>\n",
       "      <td>0</td>\n",
       "      <td>26hEOE4jqk3RmrfeAWfneg</td>\n",
       "      <td>1</td>\n",
       "      <td>Great decor and awesome food but some dishes h...</td>\n",
       "      <td>0</td>\n",
       "      <td>8x-lBENayDizUL8wXlTyOg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10845</th>\n",
       "      <td>1T6N959Q85RcNol_TuULew</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-08 18:22:08</td>\n",
       "      <td>0</td>\n",
       "      <td>E1zzDf2Y86fRIV7Z7oxrQA</td>\n",
       "      <td>1</td>\n",
       "      <td>This AAA office is a pleasure to visit. The fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>VL-KXKqEZ2682Qcs6B44Jg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27145</th>\n",
       "      <td>_gO1inMQhfXlK_S46SgGJA</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-10 01:31:39</td>\n",
       "      <td>1</td>\n",
       "      <td>FYubvyEcoi-BudnWV4MasA</td>\n",
       "      <td>-1</td>\n",
       "      <td>My wife and I came here on our wedding anniver...</td>\n",
       "      <td>2</td>\n",
       "      <td>4SM_JIV-ZUk5ZI87dTKEtQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>SoCVWvr5f5lYJEY_62bgAw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-11 20:22:27</td>\n",
       "      <td>2</td>\n",
       "      <td>iNsFMNikcmbdl7vuzKuMtg</td>\n",
       "      <td>-1</td>\n",
       "      <td>I came here at 9pm and the sign on the door sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>9D0-Jj34bTK9P3v8zSFy9w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66696</th>\n",
       "      <td>5aeFlQjZlwJhR7gA-9VMWA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-09 01:36:07</td>\n",
       "      <td>0</td>\n",
       "      <td>AnZpvCM-423W3LIVnZijuA</td>\n",
       "      <td>-1</td>\n",
       "      <td>Do not go here! We recently went to get a car ...</td>\n",
       "      <td>0</td>\n",
       "      <td>LooAeVfGYajxhtYsfdP18A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62080</th>\n",
       "      <td>8HOZJRybEinI3krJK6NHbg</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-27 13:28:16</td>\n",
       "      <td>2</td>\n",
       "      <td>bW0G_mh0OLauX-1jzVOw-Q</td>\n",
       "      <td>-1</td>\n",
       "      <td>I've been wanting LASIK for years and this pla...</td>\n",
       "      <td>40</td>\n",
       "      <td>G_Wv-inIZFSQyz98PGKfCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952</th>\n",
       "      <td>SoCVWvr5f5lYJEY_62bgAw</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-12 00:18:54</td>\n",
       "      <td>1</td>\n",
       "      <td>wH4mXLLea2IfNttDDsDh5g</td>\n",
       "      <td>1</td>\n",
       "      <td>I had to reset my Yelp password so I could lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>bj1a_mGtKwZGFwR3cmOMVg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>-hipP74BQsEFa2WnDvbi6w</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-27 20:35:13</td>\n",
       "      <td>0</td>\n",
       "      <td>sXjEffi2NcnDy2bzP2sCxA</td>\n",
       "      <td>1</td>\n",
       "      <td>Dr Desanto is amazing! He's kind and patient. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>q0Cti-VYvu8sDtGMzV2RpQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>rcaPajgKOJC2vo_l3xa42A</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-04 02:00:58</td>\n",
       "      <td>0</td>\n",
       "      <td>CkU7dYkQ2_PdMG6ztpjgxg</td>\n",
       "      <td>-1</td>\n",
       "      <td>My friends and I were very excited to have bru...</td>\n",
       "      <td>0</td>\n",
       "      <td>YPVEDPGqxIbcFElZd2iRzQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44441</th>\n",
       "      <td>H6skMpg_g-sOrfTQf_Q5LQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-19 18:20:01</td>\n",
       "      <td>0</td>\n",
       "      <td>QVkqNuBNiDCybrtX2aRp1w</td>\n",
       "      <td>-1</td>\n",
       "      <td>the food wasn't as bad as I expected it to be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>FsqkZac7zHkMKwx2WHf28Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19446</th>\n",
       "      <td>vnvQ0lD9MDje2DFde9PKQA</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-27 22:41:37</td>\n",
       "      <td>1</td>\n",
       "      <td>NW7OlAQatRwB42y5bM67Xg</td>\n",
       "      <td>-1</td>\n",
       "      <td>We'll start with no smoking, no gambling, and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>8QKrhvVqhEkD8xo4E4s0GQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54258</th>\n",
       "      <td>eqQnIjAAhOUuHqK6gTWRXw</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-18 01:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>HrROQDXgCE5TMObe8en9Tg</td>\n",
       "      <td>-1</td>\n",
       "      <td>Went for dinner today at 4pm the place was emp...</td>\n",
       "      <td>0</td>\n",
       "      <td>eK5ncNLYkwiFaQ4kxxwAvA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  cool                 date  funny  \\\n",
       "117895  1zsM7weLS8fNHomDAqCh4Q     0  2017-07-30 21:01:16      0   \n",
       "44320   yBGqf8l9NOM3vZFnlxcgzQ     1  2010-07-09 18:55:34      3   \n",
       "73075   K5sUVFSGFEZosixSXgx5sw     0  2018-06-10 21:08:51      0   \n",
       "22447   IuW6aZ8XYtxkdvHJoVHlfw     0  2011-01-09 21:18:32      0   \n",
       "30171   9Jo1pu0y2zU6ktiwQm6gNA     0  2017-06-07 02:31:32      0   \n",
       "94841   nxlgrjTdUhvTg_3Ai0JKqw     0  2017-09-10 22:25:30      0   \n",
       "14195   4IGaWH9jUYMtP2uHIFEqFQ     0  2014-04-01 17:06:26      0   \n",
       "18383   8nDEOGVVvReXFJ2zjPh4Pw     0  2013-05-09 15:57:45      0   \n",
       "13082   x8h3A9dOKux99qAp6Bakbg     0  2010-11-22 20:40:47      1   \n",
       "101896  6ZIHxvFTHC1pvAzAS0uLDA     0  2015-07-30 00:43:29      1   \n",
       "16007   J7fekWie4ZwR03AZVBisFw     0  2015-01-04 01:37:20      0   \n",
       "32213   KalAJyO0Zpg3K1wVwYXBHA     0  2014-06-13 22:04:03      0   \n",
       "75878   iuSq6jpt-r-7JxqXE5hK6g     0  2011-07-04 13:17:31      1   \n",
       "74      4ZbRwCB9oGibxK21MUZKHA     0  2018-08-04 22:27:08      0   \n",
       "27338   _iGvLfEsqDwPUxRUAe6tUw     0  2015-02-03 03:01:22      0   \n",
       "4958    6TvB1PZCY1Ap2S-yNJPs4w     0  2018-09-14 04:11:12      0   \n",
       "7059    tWiFat101ID5w_wgAPMXhA     0  2014-12-18 04:20:13      0   \n",
       "39270   LGEIsxeJQATo9J1IA-TEdA     1  2018-07-09 01:36:28      1   \n",
       "14418   nvBhlpH8TWbCl70_30gqxg     0  2017-12-16 00:17:09      1   \n",
       "63863   3GfdCuI0YCc5U3rLLLPHUw     0  2016-03-18 16:50:10      0   \n",
       "61884   u_vPjx925UPEG9DFOAAvFQ     0  2015-07-07 17:43:48      0   \n",
       "7580    _orp_eadrrigWixdMfpB9A     0  2016-10-26 22:56:58      1   \n",
       "49311   4kDLEb1OgE7IrO54lCkn3A     0  2018-07-26 20:15:53      0   \n",
       "50477   YHXczxm4W3BkGT-z7vZBBw     0  2015-10-18 14:58:10      0   \n",
       "97933   uh7DUWtPoZkuEE05fghJ_w     0  2016-12-22 05:53:56      0   \n",
       "11561   i6gKYG_YFuF5o90jPuWYvw     0  2017-03-15 02:47:56      0   \n",
       "25492   Rfu2q_Jc0fAGP_5ecIar3g     0  2012-05-29 04:13:45      0   \n",
       "28989   ppobG2P-YmqTPy0s4MTRtA     0  2016-07-15 00:51:47      0   \n",
       "11990   eaNenRk_liZBERFFLCXqqQ     0  2016-06-12 06:28:30      0   \n",
       "11376   Os1n1_idfw9vv9kwULGJnQ     0  2012-12-04 04:52:31      0   \n",
       "...                        ...   ...                  ...    ...   \n",
       "110664  ijg7qQCYnhUWBd5JUxbfvA     0  2018-08-05 20:26:03      0   \n",
       "6703    oz-U184llqjVIt398hLntQ     1  2015-03-18 19:25:15      1   \n",
       "18340   dPGs5b0N9MarZjVgQVelGQ     0  2017-11-07 02:16:32      0   \n",
       "48086   u_vPjx925UPEG9DFOAAvFQ     0  2018-04-05 02:52:10      0   \n",
       "38772   1lLJDy73uBp_I2LJ0B0Fkw     0  2011-02-16 16:50:15      0   \n",
       "44664   0j7VWa5uGebj_94C1K2i2g     0  2017-07-08 20:24:33      0   \n",
       "17089   3GfdCuI0YCc5U3rLLLPHUw     1  2014-04-21 09:38:08      0   \n",
       "8337    KUOa1acSFn6DkO9jp-sn6A     0  2017-06-06 18:52:41      1   \n",
       "18096   e1SSSU7IUrC3R_cmw4vW9g     1  2014-11-13 13:29:04      0   \n",
       "1960    k4jX-Xe9dFu2pmdnlrcwgA     0  2013-12-28 21:50:03      0   \n",
       "18942   4gwh0q7JsdzHIm_pdYUlZg    13  2013-01-03 17:18:44      0   \n",
       "33982   F2pfjAZ_3dMTGCKv6c5wOw     0  2014-07-28 21:25:37      0   \n",
       "101987  seYvTmOZGJ2IAMdfQa8pkg     0  2014-05-10 20:10:11      0   \n",
       "50685   YidWQ-CipHgGpA8jygsPpQ     0  2015-01-21 02:30:15      0   \n",
       "15252   Te8ubqIn8aH2uplVhvMntw     0  2017-01-14 22:09:51      0   \n",
       "6653    hUgaylJ8gR3BNMcFiASQSA     0  2014-11-30 01:37:56      0   \n",
       "69257   ShUh_MMkaVp_KXCtNjPvXA     0  2012-10-12 13:58:54      0   \n",
       "16237   vDqKDzGuHXBznrC1HlgW1A     0  2018-09-25 17:47:01      0   \n",
       "36281   ME6D5nLlfG0xZCtICOYDuw     0  2012-01-04 15:28:11      0   \n",
       "10845   1T6N959Q85RcNol_TuULew     0  2017-07-08 18:22:08      0   \n",
       "27145   _gO1inMQhfXlK_S46SgGJA     1  2014-09-10 01:31:39      1   \n",
       "6603    SoCVWvr5f5lYJEY_62bgAw     0  2016-04-11 20:22:27      2   \n",
       "66696   5aeFlQjZlwJhR7gA-9VMWA     0  2017-04-09 01:36:07      0   \n",
       "62080   8HOZJRybEinI3krJK6NHbg     0  2011-09-27 13:28:16      2   \n",
       "14952   SoCVWvr5f5lYJEY_62bgAw     1  2016-04-12 00:18:54      1   \n",
       "6798    -hipP74BQsEFa2WnDvbi6w     0  2017-01-27 20:35:13      0   \n",
       "1593    rcaPajgKOJC2vo_l3xa42A     0  2013-09-04 02:00:58      0   \n",
       "44441   H6skMpg_g-sOrfTQf_Q5LQ     0  2015-11-19 18:20:01      0   \n",
       "19446   vnvQ0lD9MDje2DFde9PKQA     1  2012-06-27 22:41:37      1   \n",
       "54258   eqQnIjAAhOUuHqK6gTWRXw     0  2017-03-18 01:50:00      0   \n",
       "\n",
       "                     review_id  class  \\\n",
       "117895  8HUD9mFT5ulcXWsJ0tvlHA     -1   \n",
       "44320   cVtFum2XFprf5wVQhWB6WA     -1   \n",
       "73075   -5Qc2230M8_Olotphs7BuA     -1   \n",
       "22447   olmjKR6uzlpG-8SQIcjdHw      1   \n",
       "30171   k_1ITZFaoCA-FtIrBo0LvQ      1   \n",
       "94841   gX8paNzzNOH_8RCg2gKlhA     -1   \n",
       "14195   P30fI8uVkPFmQCLJ0PqqHA      1   \n",
       "18383   7ObEq54s3BVYa4k0kW1Ktg     -1   \n",
       "13082   40IOk-VBxiq7d-KUlUlC9w     -1   \n",
       "101896  MybJ5GnsoSSDX9P8Ydoc2g     -1   \n",
       "16007   DFrsI3rLHQyDm1m6jvU18A     -1   \n",
       "32213   snl4SU-FQB9V6NEzisTbcQ     -1   \n",
       "75878   U1Zs5yQi0j_ab2LpWncTsA     -1   \n",
       "74      E5iXQGD_x_Fyee1kOKgGTw     -1   \n",
       "27338   DHXZOvG6urLihqCsdL59Lw     -1   \n",
       "4958    u_OpkjRC-wY8x16dmjgGew     -1   \n",
       "7059    T1yrvyOcdsvm0wOMNSrZww      1   \n",
       "39270   mbn_GyffLzGUTFeWwT06Xw     -1   \n",
       "14418   iUkMdJ3mdbCxhhySwIHT2A     -1   \n",
       "63863   Q1gJnlSBzfd6sxw39jjuNA     -1   \n",
       "61884   CLis0AoUs5Coi_fAye16tQ     -1   \n",
       "7580    a1E8gNIp1bs9lkUWr8m4ZA      1   \n",
       "49311   fmlVWFzycbqQDqkMIp88Ew     -1   \n",
       "50477   i5WYsZnf-r_Te_932rZwdQ     -1   \n",
       "97933   LCBBrcyQVwOoDmDEG51t4Q     -1   \n",
       "11561   QaKD8EQaiwHLAuCO42KN8g     -1   \n",
       "25492   uHnCz4_jvgcDruzb8eItoA      1   \n",
       "28989   MlyUSNbTES7bxh6oHL5zmA     -1   \n",
       "11990   aBD1oLFaTN7LAcvOVcfHaw      1   \n",
       "11376   HMhDTuz5mD6Gv9JpYm3SlQ      1   \n",
       "...                        ...    ...   \n",
       "110664  _R052l9dVVKd80aCK-BqWA     -1   \n",
       "6703    OPZKeZyhvoShzu6LRQ3kig      1   \n",
       "18340   7_D5oAsiAgFMWQfkvrgv4Q      1   \n",
       "48086   Ke_BLSjY6V12i1D5s3Ieeg     -1   \n",
       "38772   2UvBQ5XpA9FAvf9hIDSJaw      1   \n",
       "44664   oGGqWgyeNcOLYmUWfDPQWA     -1   \n",
       "17089   ndtKjKcT8Biykk3Jeb3Dag      1   \n",
       "8337    2G7GKwpWJJviVErk6-Csbw     -1   \n",
       "18096   D1IxK6Vcztw3P3CKyLek2A      1   \n",
       "1960    UUSHvjTqoQ6bPx69XtDF_g     -1   \n",
       "18942   SWEBe2_Z_Stc2R8Hu0C2LA      1   \n",
       "33982   2j9o2wkdoC4hU5ELdKKsxw      1   \n",
       "101987  RMQ9PFcEDotH8pf0FvI4mg     -1   \n",
       "50685   rHlUTLFvQgguRiK1xoF_LQ     -1   \n",
       "15252   Ltfz2_Tibu0LQVp7PJYVeQ      1   \n",
       "6653    QiXtP62NeBMnqri3d8oz-g      1   \n",
       "69257   vfkijFVcBvlcNzcMTqp-ZQ     -1   \n",
       "16237   DJyXRQl7rmqAnQGnq87IoA     -1   \n",
       "36281   26hEOE4jqk3RmrfeAWfneg      1   \n",
       "10845   E1zzDf2Y86fRIV7Z7oxrQA      1   \n",
       "27145   FYubvyEcoi-BudnWV4MasA     -1   \n",
       "6603    iNsFMNikcmbdl7vuzKuMtg     -1   \n",
       "66696   AnZpvCM-423W3LIVnZijuA     -1   \n",
       "62080   bW0G_mh0OLauX-1jzVOw-Q     -1   \n",
       "14952   wH4mXLLea2IfNttDDsDh5g      1   \n",
       "6798    sXjEffi2NcnDy2bzP2sCxA      1   \n",
       "1593    CkU7dYkQ2_PdMG6ztpjgxg     -1   \n",
       "44441   QVkqNuBNiDCybrtX2aRp1w     -1   \n",
       "19446   NW7OlAQatRwB42y5bM67Xg     -1   \n",
       "54258   HrROQDXgCE5TMObe8en9Tg     -1   \n",
       "\n",
       "                                                     text  useful  \\\n",
       "117895  Wait for a table wasn't bad for a Sunday brunc...       0   \n",
       "44320   What a disappointment!  I was all excited to s...      10   \n",
       "73075   Burger was subpar and the fries were cold, did...       1   \n",
       "22447   I love aloha salon! Not only their service is ...       1   \n",
       "30171   I only had their spicy poke bowl, but I went t...       0   \n",
       "94841   Not what I expected. It is ordinary, nothing r...       0   \n",
       "14195   This is actually one of the easier airports to...       1   \n",
       "18383   Not the best of attitudes, I thought this plac...       1   \n",
       "13082   How is In the Company of Thieves?  It depends ...       4   \n",
       "101896  I ordered a #2 pork roll sandwich.   I nearly ...       0   \n",
       "16007   My husband and I were staying at a hotel near ...       0   \n",
       "32213   Bad experience!  Blackened salmon sandwich app...       2   \n",
       "75878   I've been to Heart and Soul two times and both...       3   \n",
       "74      I went into this store yesterday and it was ho...       1   \n",
       "27338   Poor salesmanship,  deceptive during trade-in ...       1   \n",
       "4958    Aaliyah at the restaurant was super rude . May...       0   \n",
       "7059    This place is an institution. I have been goin...       0   \n",
       "39270   This place used to be 5 stars.  I've been goin...       2   \n",
       "14418   Why is this theater so filthy? Dirty! Trash an...       0   \n",
       "63863   I would have given the place a rave review if ...       0   \n",
       "61884   Very disappointed, we stayed on the 14th floor...       0   \n",
       "7580    Dr. McCoy is awesome and his team is also very...       0   \n",
       "49311   Went with a few friends since everywhere else ...       0   \n",
       "50477   I was pretty excited to hear about a new Chati...       2   \n",
       "97933   Chic.... to enjoy ambiance this is the place ....       0   \n",
       "11561   Giving them 2 stars because they have made the...       0   \n",
       "25492   Let me say this... my total package cost me $4...      14   \n",
       "28989   Maybe we were here on an off-day, but my party...       1   \n",
       "11990   I don't usually do reviews but this is 5 stars...       0   \n",
       "11376   Someone please explain what I would have done ...       0   \n",
       "...                                                   ...     ...   \n",
       "110664  Food was great. $5 Bloody Mary was Good. Beer ...       0   \n",
       "6703    As a gay male walking into this restaurant I m...       1   \n",
       "18340   Very nice place. Service tends to be very good...       0   \n",
       "48086   After a long drive we got to the hotel on 3/30...       0   \n",
       "38772   I have to admit, there is absolutley  nothing ...       0   \n",
       "44664   GOD I HATE WALMART, and this one is no excepti...       2   \n",
       "17089   One of the newer izakayas in the valley. They ...       2   \n",
       "8337    This Famous Dave's was awful!  The only reason...       1   \n",
       "18096   Un très beau et accueillant café, la meilleure...       0   \n",
       "1960    My husband and I went here after stopping at t...       0   \n",
       "18942   impeccable service. delectable food. this plac...      12   \n",
       "33982   Have been wanting to go here for quite some ti...       0   \n",
       "101987  This place needs to make up its mind! Sometime...       1   \n",
       "50685   Had an appointment to get my dogs bathed at th...       0   \n",
       "15252   The gelato tastes great. The price did not jus...       0   \n",
       "6653    Wow!  Matt Lemm from Funny Magic For Kids has ...       3   \n",
       "69257   The space is nice. The dry-rub ribs were good,...       0   \n",
       "16237   I'm very upset with this practice. I have trie...       0   \n",
       "36281   Great decor and awesome food but some dishes h...       0   \n",
       "10845   This AAA office is a pleasure to visit. The fr...       1   \n",
       "27145   My wife and I came here on our wedding anniver...       2   \n",
       "6603    I came here at 9pm and the sign on the door sa...       0   \n",
       "66696   Do not go here! We recently went to get a car ...       0   \n",
       "62080   I've been wanting LASIK for years and this pla...      40   \n",
       "14952   I had to reset my Yelp password so I could lea...       1   \n",
       "6798    Dr Desanto is amazing! He's kind and patient. ...       1   \n",
       "1593    My friends and I were very excited to have bru...       0   \n",
       "44441   the food wasn't as bad as I expected it to be ...       1   \n",
       "19446   We'll start with no smoking, no gambling, and ...       5   \n",
       "54258   Went for dinner today at 4pm the place was emp...       0   \n",
       "\n",
       "                       user_id  \n",
       "117895  F3wv7xhvjQFHAsD6mubsIQ  \n",
       "44320   6b4yYexmPQglmNdNum531Q  \n",
       "73075   zeHuIVREdQtAaiJRpb4low  \n",
       "22447   QAdtpOZjG84043dqtXfESg  \n",
       "30171   EBkNxxo181SpO1CYinI3xg  \n",
       "94841   kjzg7jTm6tWhETeJ3xDqZw  \n",
       "14195   sh3V6hnNMLVV9YwFA9QNaw  \n",
       "18383   Y8_yCJ7N7LyqqJ-rSxd4iQ  \n",
       "13082   TIll8A0a_GqegEm4h3yiHw  \n",
       "101896  oAJzUPW-XtpEQyle_QXLkA  \n",
       "16007   go0FTv1slZ128s_Y24Igdw  \n",
       "32213   0lZTY9OnTEc5gaBPRGvgeA  \n",
       "75878   NUqAqRPyWOgPDdMdhtSebw  \n",
       "74      ffMc-TmUUhEbj5LLNILB4A  \n",
       "27338   EgbeJrycEtSkps8UbJRpaQ  \n",
       "4958    nh6YUBtU-azoYVKDK8O7KQ  \n",
       "7059    Owo6mggrsd4cuKlC0wWQ6w  \n",
       "39270   Z8dN-_8IMZ3FnHg2AhGlXA  \n",
       "14418   1_CkjgX5iGjbVpW8O-GU5Q  \n",
       "63863   AdgrOZj2hrh0HlGyu7JWHg  \n",
       "61884   SENiX02vQAUqFUB-NsITmQ  \n",
       "7580    M0UiTAlVZx317KGSZ5lxLg  \n",
       "49311   ImiPjQTtcXq400p6djLrtA  \n",
       "50477   zWWcik1fRPZviBCQLC26FQ  \n",
       "97933   2qkXXaDBo_MdSBHj8Mdj0g  \n",
       "11561   zyg4-MFtfPWmwucVazSjfw  \n",
       "25492   N_8Ad4o7pgBbHDG7AC11wA  \n",
       "28989   No1Qn10ByvTfDVUKDUB3aA  \n",
       "11990   Ng5lLOfZjI-pbPbnLw5EmA  \n",
       "11376   BA46YFb2JxWvz1c1ApZ9ZQ  \n",
       "...                        ...  \n",
       "110664  mGHG6Qh6RQh4dK_eR0WRsg  \n",
       "6703    89ExXwHanHBxx04yMSZmNw  \n",
       "18340   vOPnC4XPRSknykbxYIG8Hw  \n",
       "48086   Qhmk2ieq8RpckAV8x2cD-Q  \n",
       "38772   jx4_0MDOY-FW4G7yW49WxA  \n",
       "44664   o9MwJLcMUJ48LRVIUmr6BQ  \n",
       "17089   gqpnDoFx42U5NdtejYfKOg  \n",
       "8337    w8rOqeKZCPtDu-DXXSZIwQ  \n",
       "18096   TuSA83Ob6un1m0LXl2JHnQ  \n",
       "1960    PjlYINWKAxdWvL1zz4UlJg  \n",
       "18942   zSwb7qNpSgU3ekHMpiHsOA  \n",
       "33982   j2FfSIomcaNYvv8ywEIzQA  \n",
       "101987  VFWymyNU_Bp8VCl9_RD8og  \n",
       "50685   2eNy5pf5ctWxouGGaASTOQ  \n",
       "15252   2pRDsLUqTK0o9ePcIiyy_A  \n",
       "6653    SBhmnRD-w_xgQ-RQRRCz5w  \n",
       "69257   7tRj6BKT1tTlZ1AbmZWAmw  \n",
       "16237   -fwrHX9L3a0IlU3wkhxd2w  \n",
       "36281   8x-lBENayDizUL8wXlTyOg  \n",
       "10845   VL-KXKqEZ2682Qcs6B44Jg  \n",
       "27145   4SM_JIV-ZUk5ZI87dTKEtQ  \n",
       "6603    9D0-Jj34bTK9P3v8zSFy9w  \n",
       "66696   LooAeVfGYajxhtYsfdP18A  \n",
       "62080   G_Wv-inIZFSQyz98PGKfCw  \n",
       "14952   bj1a_mGtKwZGFwR3cmOMVg  \n",
       "6798    q0Cti-VYvu8sDtGMzV2RpQ  \n",
       "1593    YPVEDPGqxIbcFElZd2iRzQ  \n",
       "44441   FsqkZac7zHkMKwx2WHf28Q  \n",
       "19446   8QKrhvVqhEkD8xo4E4s0GQ  \n",
       "54258   eK5ncNLYkwiFaQ4kxxwAvA  \n",
       "\n",
       "[40000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get one star reviews and label them with -1\n",
    "dfOnes = df[df['stars'] == 1]\n",
    "dfOnes = dfOnes.head(10000)\n",
    "dfOnes['stars'] = dfOnes['stars'].apply(lambda x: -1)\n",
    "\n",
    "\n",
    "dfTwos = df[df['stars'] == 2]\n",
    "dfTwos = dfTwos.head(10000)\n",
    "dfTwos['stars'] = dfTwos['stars'].apply(lambda x: -1)\n",
    "\n",
    "# Get five star reviews and label them with 1\n",
    "print(\"Shape of the ones input: \")\n",
    "print(dfOnes.shape)\n",
    "\n",
    "dfFives = df[df['stars'] == 5]\n",
    "dfFives = dfFives.head(10000)\n",
    "dfFives['stars'] = dfFives['stars'].apply(lambda x: 1)\n",
    "\n",
    "dfFours = df[df['stars'] == 4]\n",
    "dfFours = dfFours.head(10000)\n",
    "dfFours['stars'] = dfFours['stars'].apply(lambda x: 1)\n",
    "\n",
    "print(\"Shape of the fives input: \")\n",
    "print(dfFives.shape)\n",
    "dfCombined = pd.concat([dfOnes, dfTwos, dfFours, dfFives], axis=0)\n",
    "dfCombined=dfCombined.rename(columns = {'stars':'class'})\n",
    "dfTwos=dfTwos.rename(columns = {'stars':'class'})\n",
    "dfFours=dfFours.rename(columns = {'stars':'class'})\n",
    "dfCombined = dfCombined.sample(frac=1)\n",
    "\n",
    "dfTrainset = dfCombined.head(int(len(dfCombined.index) * .8))\n",
    "dfTestset = dfCombined.tail(int(len(dfCombined.index) * .2))\n",
    "\n",
    "trainX = np.asarray(dfTrainset['text'])\n",
    "trainY = np.asarray(dfTrainset['class'])\n",
    "\n",
    "testX = np.asarray(dfTestset['text'])\n",
    "testY = np.asarray(dfTestset['class'])\n",
    "\n",
    "print('Data Frame of reviews:')\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part K: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[1713 2278]\n",
      " [1106 2903]]\n",
      "0.577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.577"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "currBaselineFeaturized_data = np.array(list(map(baseline_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "currBaselineModel = trainModel(currBaselineFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBaseline_data = np.array(list(map(baseline_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(currBaselineModel, testFeaturizedBaseline_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: The accuracy for the baseline model was 0.577, similar to before, meaning that length of message is better than randomly guessing but not enough to do too much better.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part L: Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[3676  315]\n",
      " [ 299 3710]]\n",
      "0.92325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92325"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "currBagFeaturized_data = np.array(list(map(bag_of_words_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "currBagModel = trainModel(currBagFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBag_data = np.array(list(map(bag_of_words_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(currBagModel, testFeaturizedBag_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: The accuracy of the initial bag of words model is 0.923 which is significantly lower than the acccuracy when run on the dataset with just 1's and 5's. This makes sense as there is more nuance now so the model will have more difficulty classifying.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part M: Binary Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[3673  318]\n",
      " [ 295 3714]]\n",
      "0.923375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.923375"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "currBinBagFeaturized_data = np.array(list(map(bag_of_words_binary_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "currBinBagModel = trainModel(currBinBagFeaturized_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedBinBag_data = np.array(list(map(bag_of_words_binary_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(currBinBagModel, testFeaturizedBinBag_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected? How did it compare to the regular Bag of Words model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: The accuracy with binary bag of words is slightly higher at 0.9234 vs 0.933 from before, so the model did improve with binary bag of words as expected but not by too much. This is because with longer reviews binary bag of words will weight a certain few stronger words much higher based on their presence.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part N: Negative Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[3690  319]\n",
      " [ 288 3703]]\n",
      "0.924125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.924125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "neg_data = np.array(list(map(bag_of_words_neg_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "negModel = trainModel(neg_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedNeg_data = np.array(list(map(bag_of_words_neg_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(negModel, testFeaturizedNeg_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected? How did it compare to the regular Bag of Words model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: This accuracy of 0.924 is higher than both the normal Bag of Words and Binary Bag of Words that were just run. This is because it enables us to account for negatives like \"not good\" but the difference is still not a very large margin.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part O: Negative Binary Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Train Featurization\n",
      "Beginning Training\n",
      "Beginning Test Featurization\n",
      "Accuracy:\n",
      "[[3798  211]\n",
      " [ 176 3815]]\n",
      "0.951625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.951625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Beginning Train Featurization\")\n",
    "negbin_data = np.array(list(map(bag_of_words_neg_binary_featurize, trainX)))\n",
    "print(\"Beginning Training\")\n",
    "negBinModel = trainModel(negbin_data, np.asarray(dfTrainset[\"class\"]))\n",
    "print(\"Beginning Test Featurization\")\n",
    "testFeaturizedNegBin_data = np.array(list(map(bag_of_words_neg_binary_featurize, testX)))\n",
    "print(\"Accuracy:\")\n",
    "accuracyData(negBinModel, testFeaturizedNegBin_data, np.asarray(dfTestset[\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was your accuracy percentage? Was it what you expected? How did it compare to the regular Bag of Words model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESPONSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Yelp Reviews: The accuracy of 0.952 is significantly higher than any of the models so far. The combination of both the corrections for binary bag of words and allowing for negation did much better together than either of them individually. Ultimately, it can be seen that when the dataset gets more convoluted and the binary classification is not clearly divided the original Bag of Words featurization may not do as well as expected. Instead, modifications like the ones we made for binary Bag of Words and providing additional features for negation have the potential to result in large improvements in model performance and thus should be determined in an experimen. Additional summary level features can and should be added in order to improve the model further, such as length, punctuation, other dictionaries, and more.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
